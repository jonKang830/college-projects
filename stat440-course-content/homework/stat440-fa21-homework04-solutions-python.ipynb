{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd7c569-5031-4fff-8f00-6a86c06b9cad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# STAT 440 Statistical Data Management - Fall 2021\n",
    "## Homework04\n",
    "### Due: Wednesday November 03, 2021 11:59 pm US Central Time\n",
    "#### Created by Course Staff\n",
    "\n",
    "Grading Rubric (per question):  \n",
    "2 points if complete and correct  \n",
    "1 point if incomplete or incorrect  \n",
    "0 points if no attempt made  \n",
    "\n",
    "\n",
    "**Retrieving your work**\n",
    "\n",
    "This and all future homework .md files are written in Markdown. The .md file is rendered as an .html file for easier viewing. This and all future homework assignments are located in the **homework** directory within the **stat440-fa21-course-content** repo, i.e. **stat440-fa21-course-content/homework** in GHE. It is always recommended that you **pull** (or refresh) the **stat440-fa21-course-content** repo to ensure that you have the most updated version of all course content including the homework assignments. After pulling (or refreshing) the **stat440-fa21-course-content** repo, the homework file will be in the homework directory. Once you have accessed the .md file, copy all text from the .md file and paste all text into your reproducible document file (either .Rmd or .ipynb file). \n",
    "\n",
    "**Submitting your work**\n",
    "\n",
    "In your individual student repo (named as your netID), you are to submit ***two*** files:\n",
    "\n",
    "a. Your reproducible document file (either .Rmd or .ipynb file) which should be saved as homework##-netID.Rmd or homework##-netID.ipynb depending on your preferred software. For example, my homework 01 file would be saved as homework01-kinson2.Rmd.\n",
    "\n",
    "b. Your rendered reproducible document file (.html) which should be saved as homework##-netID.html. For example, my homework 01 file would be saved as homework01-kinson2.html.\n",
    "\n",
    "**Do not place your files in a sub-directory (or folder).** You have an unlimited number of submissions, but only the latest proper submission (commit and push) will be viewed and graded. You are allowed to only use one software language per homework file. This means that you cannot mix software languages (R and Python) in one single homework file. **Remember the .Rmd (or .ipynb) file needs to render properly to .html before submitting.** \n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "Undergraduates are expected to complete the problems **#1-#8**. Graduate students are expected to complete all problems.\n",
    "\n",
    "**The following problems should be completed by you as an individual. If any problem asks you a particular question, be sure to answer it completely (with code, written sentences, or both). Written sentences should not appear in code chunks or code cells. Written sentences should appear in Markdown syntax unless specifically stated otherwise.**\n",
    "\n",
    "***Do not change anything in this file above the double line. Doing so will prevent your homework from being graded.***\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "### Use only one programming language for this entire homework assignment. Use the URLs to access the data (if any). No local files allowed.\n",
    "\n",
    "**#1** (Markdown) Using Markdown syntax, make a numbered list with your first name in normal text as the first item and your last name in bold text as the second item.\n",
    "\n",
    "Answers will vary, but must be a numbered list. Graded for completeness. For example,\n",
    "\n",
    "1. Chris\n",
    "\n",
    "2. **Kinson**\n",
    "\n",
    "**#2** (Loops and conditional execution, Summarizing data, Markdown) \n",
    "\n",
    "statement: **For loops** can be used to handle grouped data summarization. \n",
    "\n",
    "If the text in bold is the term that makes the statement true, then write TRUE below in all caps. If the text in bold is the term that makes the statement false, then write FALSE below in all caps and write the correct term in bold text in a new line under FALSE.\n",
    "\n",
    "TRUE\n",
    "\n",
    "**#3** (Validating data, Cleaning data, Markdown) \n",
    "\n",
    "statement: **Condition-controlled loops** are those in which repetitive actions are repeated for a predetermined number of times and stopped when the that number of times is reached. \n",
    "\n",
    "If the text in bold is the term that makes the statement true, then write TRUE below in all caps. If the text in bold is the term that makes the statement false, then write FALSE below in all caps and write the correct term in bold text in a new line under FALSE.\n",
    "\n",
    "FALSE\n",
    "\n",
    "**index-controlled loops**\n",
    "\n",
    "**#4** (Accessing and importing data) Import the subsets of the IRI Academic Data (existing as three separate data sets) and print the structure of each separate data set using one programming language and the data URLs below. Additionally, you should read the data keys in the [data key GHE link](https://github-dev.cs.illinois.edu/stat440-fa21/stat440-fa21-course-content/raw/master/data/iri-data-key.pdf) or [data key Box link](https://uofi.box.com/shared/static/pg7u97n4rkqql5o0bg736zumrn8n1lgg.pdf) and the data description below:\n",
    "\n",
    "- [ads-demo - GHE data URL](https://github-dev.cs.illinois.edu/stat440-fa21/stat440-fa21-course-content/raw/master/data/ads-demo440-data.csv) or [ads-demo - Box data URL](https://uofi.box.com/shared/static/9b9ecldtxkr23wb3uc36wwbn2l5ylpyx.csv)\n",
    "\n",
    "- [trips - GHE data URL](https://github-dev.cs.illinois.edu/stat440-fa21/stat440-fa21-course-content/raw/master/data/trips440-data.txt) or [trips - Box data URL](https://uofi.box.com/shared/static/0pyqnfpl40kr5do7fue8t85vva11ynjm.txt)\n",
    "\n",
    "- [delivery-stores - GHE data URL](https://github-dev.cs.illinois.edu/stat440-fa21/stat440-fa21-course-content/raw/master/data/delivery-stores440-data) or [delivery-stores - Box data URL](https://uofi.box.com/shared/static/o2bqah52ioj0p0q4msvna7ixk8d9lsh4)\n",
    "\n",
    "  - The data represent sales information and customer demographics captured from select markets in the US in the year 2001, where the weeks are coded. The ads-demo data (a .csv file) contain 13983 observations and 20 columns that inform on customer (\"panelist\") demographics. Panelist ID is a unique identifier. The trips data (a .txt file) contain 730040 observations and 4 columns that inform on panelist shopping frequency and how much was spent. Panelists may shop at the same store multiple times in a given time period. The delivery-stores data (a file with no extension) contain 1575 observations and 7 columns that inform on the market that the store is in and estimates how much that store sells annually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb52c6c-3b7b-4e6e-9e58-0da9229dda51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13983 entries, 0 to 13982\n",
      "Data columns (total 20 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   Panelist ID                           13983 non-null  int64  \n",
      " 1   Panelist Type                         13983 non-null  int64  \n",
      " 2   Combined Pre-Tax Income of HH         13983 non-null  int64  \n",
      " 3   Family Size                           13983 non-null  int64  \n",
      " 4   HH_RACE                               13983 non-null  int64  \n",
      " 5   Type of Residential Possession        13983 non-null  int64  \n",
      " 6   Age Group Applied to Male HH          13983 non-null  int64  \n",
      " 7   Education Level Reached by Male HH    13983 non-null  int64  \n",
      " 8   Occupation Code of Male HH            13983 non-null  int64  \n",
      " 9   Male Working Hour Code                13983 non-null  int64  \n",
      " 10  Age Group Applied to Female HH        13983 non-null  int64  \n",
      " 11  Education Level Reached by Female HH  13983 non-null  int64  \n",
      " 12  Occupation Code of Female HH          13983 non-null  int64  \n",
      " 13  Female Working Hour Code              13983 non-null  int64  \n",
      " 14  Number of Dogs                        13983 non-null  int64  \n",
      " 15  Number of Cats                        13983 non-null  int64  \n",
      " 16  Children Group Code                   13983 non-null  int64  \n",
      " 17  Marital Status                        13983 non-null  int64  \n",
      " 18  Number of TVs Used by HH              5609 non-null   float64\n",
      " 19  Number of TVs Hooked to Cable         5442 non-null   float64\n",
      "dtypes: float64(2), int64(18)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ads = pd.read_csv(\"https://uofi.box.com/shared/static/buv7xuweoq51zw4obcf2netx4d16295h.csv\")\n",
    "ads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05633a4b-c562-4383-919a-2ea3b57407b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 730040 entries, 0 to 730039\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   PANID     730040 non-null  int64  \n",
      " 1   WEEK      730040 non-null  int64  \n",
      " 2   IRI_Key   730040 non-null  int64  \n",
      " 3   CENTS999  730040 non-null  float64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 22.3 MB\n"
     ]
    }
   ],
   "source": [
    "trips = pd.read_csv(\"https://uofi.box.com/shared/static/wmsx1tvrrncryf0ue7ldp4szhizdb3gf.txt\", sep=\"\\t\")\n",
    "trips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0454e0-a749-4541-909b-e44ebdafcf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1575 entries, 0 to 1574\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   IRI_KEY      1575 non-null   int64  \n",
      " 1   OU           1575 non-null   object \n",
      " 2   EST_ACV      1575 non-null   float64\n",
      " 3   Market_Name  1575 non-null   object \n",
      " 4   Open         1575 non-null   int64  \n",
      " 5   Clsd         1575 non-null   int64  \n",
      " 6   MskdName     1575 non-null   object \n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 86.3+ KB\n"
     ]
    }
   ],
   "source": [
    "delivery = pd.read_csv(\"https://uofi.box.com/shared/static/56bzob5ub1pu5im5fgm1125e4xocbwj2\",sep=\" \")\n",
    "delivery.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a4012-3f6c-4ac0-8f51-77cb7db346f2",
   "metadata": {},
   "source": [
    "**#5** (Data reduction, Data expansion, Summarizing data) Beginning with the **trips** data set and the information in the link in **Problem 4**, use a programming language to create a new data object named `big_spender` that does the following in this order:  \n",
    "\n",
    "1. mutates a new column called \"dollars999\" which converts the cents values in \"cents999\" to dollars\n",
    "\n",
    "2. de-selects the week column\n",
    "\n",
    "3. computes the total dollars spent per panelist ID\n",
    "\n",
    "4. filters the panelists that spend over $15000 in 2001\n",
    "\n",
    "Now, print the resulting `big_spender` data.\n",
    "\n",
    "**What's important here is that we can see the total dollars spent and which panelist spent that amount. Of other columns are present, we won't deduct for that.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca2681c-0167-42c8-85ac-43370b8beb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PANID</th>\n",
       "      <th>sum_dollars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>1128587</td>\n",
       "      <td>15876.646788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>1129452</td>\n",
       "      <td>16602.288816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>1182873</td>\n",
       "      <td>15958.847199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>1408500</td>\n",
       "      <td>15533.598120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PANID   sum_dollars\n",
       "615   1128587  15876.646788\n",
       "654   1129452  16602.288816\n",
       "1910  1182873  15958.847199\n",
       "4225  1408500  15533.598120"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips2 = trips\n",
    "trips2['dollars999'] = trips2['CENTS999']/100\n",
    "trips2 = trips2.drop(columns='WEEK')\n",
    "big_spender = trips.groupby(by='PANID')['dollars999'].sum().reset_index()\n",
    "big_spender.columns = ['PANID','sum_dollars'] # rename the columns\n",
    "big_spender = big_spender[big_spender['sum_dollars']>15000]\n",
    "big_spender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2209c92-c600-4053-8531-e6dae2ccacaf",
   "metadata": {},
   "source": [
    "**#6** (Data reduction, Data expansion, Combining data, Markdown) Use the `big_spender` data, any of the data sets in **Problem 4**, the information in the link in **Problem 4**, and a programming language applying data management concepts to answer the following question in Markdown syntax and complete sentence(s): \n",
    "\n",
    "- Which market (location) do the panelists in `big_spender` shop in?\n",
    "\n",
    "**You must answer in Markdown syntax in a complete sentence and show code as evidence of your answer.**\n",
    "\n",
    "All panelists shop in Pittsfield. **There's no way to get the market location without first joining the trips and delivery stores data together, then joining that object with the big spender data. That last join is to match the panelists from big spender with those market locations.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b59a69cd-2a35-47fc-8b0f-4c93d922be75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PANID</th>\n",
       "      <th>Market_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1129452</td>\n",
       "      <td>PITTSFIELD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1182873</td>\n",
       "      <td>PITTSFIELD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>1408500</td>\n",
       "      <td>PITTSFIELD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>1128587</td>\n",
       "      <td>PITTSFIELD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PANID Market_Name\n",
       "0     1129452  PITTSFIELD\n",
       "285   1182873  PITTSFIELD\n",
       "899   1408500  PITTSFIELD\n",
       "1183  1128587  PITTSFIELD"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips0 = trips.rename(columns={'IRI_Key':'IRI_KEY'})\n",
    "comb0 = trips0.merge(delivery,on='IRI_KEY')\n",
    "comb0.merge(big_spender,on='PANID').drop_duplicates(['PANID'],keep='first')[['PANID', 'Market_Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a180a7da-6588-45b9-ab0a-59470e8ea51b",
   "metadata": {},
   "source": [
    "**#7** (Data reduction, Data expansion, Summarizing data, Regular expressions and string manipulation) Beginning with the **delivery-stores** data set and the information in the link in **Problem 4**, use a programming language to create a new data object named `southern_grocery` that does the following (in this order):  \n",
    "\n",
    "1. filters markets in southern places including: Atlanta, Birmingham, Charlotte, Dallas, Durham, Houston, Knoxville, Mississippi, Montgomery, New Orleans, Norfolk, Raleigh, Richmond, South Carolina\n",
    "\n",
    "2. mutates a new column called \"single_state_market\" which equals \"YES\" if the market name is only the name of a state and \"NO\" otherwise\n",
    "\n",
    "3. renames any market name that contains a city name then comma then state abbreviation to only contain the city name (e.g. \"Urbana, IL\" becomes \"Urbana\")\n",
    "\n",
    "4. renames any market name that contains a forward slash to contain a space ampersand space (e.g. \"Urbana/Champaign\" becomes \"Urbana & Champaign\")\n",
    "\n",
    "5. arranges by market name in alphabetical order\n",
    "\n",
    "Now, print the first 5 observations and last 5 observations of `southern_grocery`.\n",
    "\n",
    "```{r}\n",
    "southern_grocery <- delivery %>%\n",
    "  filter(Market_Name==\"ATLANTA\" | Market_Name==\"BIRMINGHAM/MONTG.\" | Market_Name==\"CHARLOTTE\" | Market_Name==\"DALLAS, TX\" | Market_Name==\"RALEIGH/DURHAM\" | Market_Name==\"HOUSTON\" | Market_Name==\"KNOXVILLE\" | Market_Name==\"MISSISSIPPI\" | Market_Name==\"NEW ORLEANS, LA\" | Market_Name==\"RICHMOND/NORFOLK\" | Market_Name==\"SOUTH CAROLINA\") %>%\n",
    "  mutate(single_state_market = ifelse(Market_Name==\"MISSISSIPPI\" | Market_Name==\"SOUTH CAROLINA\" ,\"YES\",\"NO\")) %>%\n",
    "  mutate(market1=str_remove(Market_Name, \"\\\\,\\\\w+|\\\\,\\\\s\\\\w+\"),\n",
    "         market2=str_replace(market1, \"\\\\/\", \" & \")) %>%\n",
    "  select(-c(Market_Name,market1)) %>%\n",
    "  rename(Market=market2) %>%\n",
    "  arrange(Market)\n",
    "\n",
    "head(southern_grocery, 5)\n",
    "\n",
    "tail(southern_grocery, 5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daae81e6-4fa1-4d15-95df-ea812244d0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kinson2\\AppData\\Local\\Temp/ipykernel_13104/557028854.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  southern_grocery['single_state_market'] = [\"YES\" if ((x=='MISSISSIPPI') or (x=='SOUTH CAROLINA')) else 'NO'\n",
      "C:\\Users\\kinson2\\AppData\\Local\\Temp/ipykernel_13104/557028854.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  southern_grocery['market1'] = southern_grocery['Market_Name'].str.replace('\\,\\w+|\\,\\w\\w+','')\n",
      "C:\\Users\\kinson2\\AppData\\Local\\Temp/ipykernel_13104/557028854.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  southern_grocery['market1'] = southern_grocery['Market_Name'].str.replace('\\,\\w+|\\,\\w\\w+','')\n",
      "C:\\Users\\kinson2\\AppData\\Local\\Temp/ipykernel_13104/557028854.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  southern_grocery['market2'] = southern_grocery['market1'].str.replace('\\/,\\w\\w+',' & ')\n",
      "C:\\Users\\kinson2\\AppData\\Local\\Temp/ipykernel_13104/557028854.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  southern_grocery['market2'] = southern_grocery['market1'].str.replace('\\/,\\w\\w+',' & ')\n"
     ]
    }
   ],
   "source": [
    "southern_grocery = delivery[delivery.apply(lambda x:x.Market_Name in [\"ATLANTA\",\"BIRMINGHAM/MONTG.\",\"CHARLOTTE\",\"DALLAS, TX\",\n",
    "                                                 \"RALEIGH/DURHAM\",\"HOUSTON\",\"KNOXVILLE\",\"MISSISSIPPI\",\n",
    "                                                 \"NEW ORLEANS, LA\",\"RICHMOND/NORFOLK\",\"SOUTH CAROLINA\"],axis=1)]\n",
    "\n",
    "southern_grocery['single_state_market'] = [\"YES\" if ((x=='MISSISSIPPI') or (x=='SOUTH CAROLINA')) else 'NO'\n",
    "                                          for x in southern_grocery['Market_Name']]\n",
    "southern_grocery['market1'] = southern_grocery['Market_Name'].str.replace('\\,\\w+|\\,\\w\\w+','')\n",
    "southern_grocery['market2'] = southern_grocery['market1'].str.replace('\\/,\\w\\w+',' & ')\n",
    "southern_grocery = southern_grocery.drop(columns=['Market_Name','market1']).rename(columns={'market2':'Market'})\n",
    "southern_grocery = southern_grocery.sort_values(by='Market',kind='mergesort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04d8d3ef-be62-442a-89e9-35371108989d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IRI_KEY</th>\n",
       "      <th>OU</th>\n",
       "      <th>EST_ACV</th>\n",
       "      <th>Open</th>\n",
       "      <th>Clsd</th>\n",
       "      <th>MskdName</th>\n",
       "      <th>single_state_market</th>\n",
       "      <th>Market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>205969</td>\n",
       "      <td>GR</td>\n",
       "      <td>15.81100</td>\n",
       "      <td>958</td>\n",
       "      <td>9998</td>\n",
       "      <td>Chain54</td>\n",
       "      <td>NO</td>\n",
       "      <td>ATLANTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>213109</td>\n",
       "      <td>GR</td>\n",
       "      <td>9.37500</td>\n",
       "      <td>1123</td>\n",
       "      <td>1298</td>\n",
       "      <td>Chain126</td>\n",
       "      <td>NO</td>\n",
       "      <td>ATLANTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>223492</td>\n",
       "      <td>GR</td>\n",
       "      <td>44.04999</td>\n",
       "      <td>461</td>\n",
       "      <td>1129</td>\n",
       "      <td>Chain69</td>\n",
       "      <td>NO</td>\n",
       "      <td>ATLANTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>232419</td>\n",
       "      <td>GR</td>\n",
       "      <td>14.21100</td>\n",
       "      <td>1140</td>\n",
       "      <td>1392</td>\n",
       "      <td>Chain54</td>\n",
       "      <td>NO</td>\n",
       "      <td>ATLANTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>239874</td>\n",
       "      <td>GR</td>\n",
       "      <td>11.32100</td>\n",
       "      <td>435</td>\n",
       "      <td>1215</td>\n",
       "      <td>Chain16</td>\n",
       "      <td>NO</td>\n",
       "      <td>ATLANTA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     IRI_KEY  OU   EST_ACV  Open  Clsd  MskdName single_state_market   Market\n",
       "77    205969  GR  15.81100   958  9998   Chain54                  NO  ATLANTA\n",
       "114   213109  GR   9.37500  1123  1298  Chain126                  NO  ATLANTA\n",
       "204   223492  GR  44.04999   461  1129   Chain69                  NO  ATLANTA\n",
       "318   232419  GR  14.21100  1140  1392   Chain54                  NO  ATLANTA\n",
       "437   239874  GR  11.32100   435  1215   Chain16                  NO  ATLANTA"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "southern_grocery.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9d6299a-45e4-4160-a69f-456c1e137e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IRI_KEY</th>\n",
       "      <th>OU</th>\n",
       "      <th>EST_ACV</th>\n",
       "      <th>Open</th>\n",
       "      <th>Clsd</th>\n",
       "      <th>MskdName</th>\n",
       "      <th>single_state_market</th>\n",
       "      <th>Market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>655979</td>\n",
       "      <td>GR</td>\n",
       "      <td>2.914000</td>\n",
       "      <td>1161</td>\n",
       "      <td>1168</td>\n",
       "      <td>Chain51</td>\n",
       "      <td>YES</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>656680</td>\n",
       "      <td>GR</td>\n",
       "      <td>17.246990</td>\n",
       "      <td>1128</td>\n",
       "      <td>1334</td>\n",
       "      <td>Chain54</td>\n",
       "      <td>YES</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>657981</td>\n",
       "      <td>GR</td>\n",
       "      <td>8.090996</td>\n",
       "      <td>1129</td>\n",
       "      <td>1157</td>\n",
       "      <td>Chain135</td>\n",
       "      <td>YES</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>684049</td>\n",
       "      <td>GR</td>\n",
       "      <td>19.265990</td>\n",
       "      <td>1142</td>\n",
       "      <td>1353</td>\n",
       "      <td>Chain130</td>\n",
       "      <td>YES</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>687960</td>\n",
       "      <td>GR</td>\n",
       "      <td>7.282997</td>\n",
       "      <td>1129</td>\n",
       "      <td>9998</td>\n",
       "      <td>Chain135</td>\n",
       "      <td>YES</td>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IRI_KEY  OU    EST_ACV  Open  Clsd  MskdName single_state_market  \\\n",
       "1494   655979  GR   2.914000  1161  1168   Chain51                 YES   \n",
       "1501   656680  GR  17.246990  1128  1334   Chain54                 YES   \n",
       "1508   657981  GR   8.090996  1129  1157  Chain135                 YES   \n",
       "1540   684049  GR  19.265990  1142  1353  Chain130                 YES   \n",
       "1545   687960  GR   7.282997  1129  9998  Chain135                 YES   \n",
       "\n",
       "              Market  \n",
       "1494  SOUTH CAROLINA  \n",
       "1501  SOUTH CAROLINA  \n",
       "1508  SOUTH CAROLINA  \n",
       "1540  SOUTH CAROLINA  \n",
       "1545  SOUTH CAROLINA  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "southern_grocery.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ccf0f8-cc8e-47d3-91cc-6806f0d1f061",
   "metadata": {},
   "source": [
    "**#8** (Data reduction, Data expansion, Combining data, Markdown) Use the data in **Problem 4**, the information in the link in **Problem 4*, and a programming language applying data management concepts to answer the following question in Markdown syntax and complete sentence(s): \n",
    "\n",
    "- Among the panelists with at least one child aged 0-17 years, which panelists spend at least one hundred dollars at each of at least 3 different grocery stores within the first 40 weeks of the year?\n",
    "\n",
    "**You must answer in Markdown syntax in a complete sentence and show code as evidence of your answer.**\n",
    "\n",
    "I count 727 unique panelists with at least one child aged 0-17 years and who spend at least one hundred dollars in each of at least 3 grocery stores in the first 40 weeks of the year. **Some students may have interpreted this question as at least $100 in a single trip to the grocery store. That's acceptable here, but that means their answer is going to be different from 727 panelists. Joining only two of the datasets together wouldn't quite work out because we need to ensure that the stores are grocery stores; that information is in the delivery stores data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3f9a7d2-ac0f-49a9-b563-b826af0fe441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat1 = ads[(ads['Children Group Code']<8) & (ads['Children Group Code']>0)].rename(columns={'Panelist ID':'PANID'})\n",
    "subdat2 = trips[trips['WEEK']<1154].rename(columns={'IRI_Key':'IRI_KEY'})\n",
    "dat2 = subdat2.groupby(['PANID','IRI_KEY'])['CENTS999'].agg(\n",
    "    totdols=lambda x: sum(x)/100)\n",
    "dat2 = pd.DataFrame(dat2).reset_index()\n",
    "dat2deliv = dat2.merge(delivery,on='IRI_KEY',how='inner')\n",
    "dat2deliv = dat2deliv[(dat2deliv['OU']=='GR')&(dat2deliv['totdols']>=100)]\n",
    "dat2deliv['n'] = dat2deliv['IRI_KEY'].groupby(dat2deliv['PANID']).transform('count')\n",
    "dat2deliv = dat2deliv[dat2deliv['n']>2]\n",
    "dat1dat2deliv = dat2deliv.merge(dat1,on='PANID',how='inner')\n",
    "z = dat1dat2deliv[['PANID', 'Children Group Code', 'totdols', 'IRI_KEY', 'n']].sort_values(['PANID'])\n",
    "z2 = z.merge(delivery,on='IRI_KEY',how='inner')[['PANID', 'Children Group Code', 'totdols', 'IRI_KEY', 'n','OU']].sort_values(['PANID'],kind='mergesort')\n",
    "import numpy as np\n",
    "len(np.unique(z2['PANID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6005c323-8d53-47aa-8c53-d4a724b3df95",
   "metadata": {},
   "source": [
    "**#9** (Data reduction, Data expansion, Combining data, Markdown) Use the data in **Problem 4**, the information in the link in **Problem 4*, and a programming language applying data management concepts to answer the following question in Markdown syntax and complete sentence(s):  \n",
    "\n",
    "- Among any panelists who shop at the same grocery stores, how many panelists - who are renting their homes -  spend more than five hundred dollars in the first 6 months of the year?\n",
    "\n",
    "**You must answer in Markdown syntax in a complete sentence and show code as evidence of your answer. The statement \"among any panelists who shop at the same grocery stores\" means if two people shop at Store1 and 5 people shop at Store2 then these 7 panelists should be included in the result. **\n",
    "\n",
    "Among any panelists who shop at the same grocery stores, I count 1093 panelists who are renting their homes and spending more than five hundred dollars in the first 6 months of the year. I count 14 unique grocery stores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04683492-a9b8-4917-9c0e-341250b026c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652159    8549\n",
       "248128    7859\n",
       "213290    5687\n",
       "233779    4129\n",
       "653776    4048\n",
       "259111    1401\n",
       "257871    1231\n",
       "648764    1230\n",
       "264075     873\n",
       "234140     862\n",
       "257006     775\n",
       "228037     767\n",
       "266596     751\n",
       "200564     340\n",
       "Name: IRI_KEY, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads0 = ads.rename(columns={'Panelist ID':'PANID'})\n",
    "trips0 = trips.rename(columns={'IRI_Key':'IRI_KEY'})\n",
    "combo_trips_deliv = trips0.merge(delivery,on='IRI_KEY',how='inner')\n",
    "combo_all = ads0.merge(combo_trips_deliv,on='PANID',how='inner')\n",
    "sub = combo_all[(combo_all['WEEK']<1140) & (combo_all['Type of Residential Possession']==1) & (combo_all['OU']=='GR')]\n",
    "x0 = pd.DataFrame(sub.groupby(['PANID', 'IRI_KEY'])['CENTS999'].agg(totdols=lambda x: round(sum(x)/100,2))).reset_index()\n",
    "x = sub.merge(x0,on=['PANID', 'IRI_KEY'])\n",
    "x = x[x['totdols']>500]\n",
    "x['IRI_KEY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e1267a-03b0-4ba5-abfa-b2d291af1c6c",
   "metadata": {},
   "source": [
    "**#10** (Data reduction, Data expansion, Combining data, Markdown) Use the data in **Problem 4**, the information in the link in **Problem 4*, and a programming language applying data management concepts to answer the following question in Markdown syntax and complete sentence(s):  \n",
    "\n",
    "- Which panelists - with more than one person living in their household - spend at least $1000 at each of 2 or more stores (if any)? \n",
    "\n",
    "**You must answer in Markdown syntax in a complete sentence and show code as evidence of your answer.**\n",
    "\n",
    "I count 1223 panelists - with more than one person living in their household - who spend at least $1000 at 2 or more stores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8130c719-f8f8-437f-a5f9-5dfeceab380a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads0 = ads.rename(columns={'Panelist ID':'PANID'})\n",
    "trips0 = trips.rename(columns={'IRI_Key':'IRI_KEY'})\n",
    "combo_trips_deliv = trips0.merge(delivery,on='IRI_KEY',how='inner')\n",
    "combo_all = ads0.merge(combo_trips_deliv,on='PANID',how='inner')\n",
    "\n",
    "x = combo_all[(combo_all['Family Size']>1) & (combo_all['OU']=='GR')]\n",
    "# create a new data frame restoring total spending amount for each ('PANID', 'IRI_KEY')\n",
    "tot = pd.DataFrame(x.groupby(['PANID', 'IRI_KEY'])['CENTS999'].agg(totdols=lambda x: round(sum(x)/100,2))).reset_index()\n",
    "# merge new variable into x\n",
    "x = x.merge(tot,on=['PANID','IRI_KEY'],how='inner')\n",
    "x = x[x['totdols']>=1000]\n",
    "x = x[['PANID', 'Family Size', 'totdols', 'IRI_KEY']]\n",
    "# count the number of unique IRI_KEY for each PANID\n",
    "x['n'] = x['IRI_KEY'].groupby(x['PANID']).transform('nunique')\n",
    "x = x.drop_duplicates(['PANID','IRI_KEY'],keep='first')\n",
    "x = x[x['n']>1].sort_values('PANID')\n",
    "len(x['PANID'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

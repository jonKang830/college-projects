{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT 440 Statistical Data Management - Fall 2021\n",
    "## Week 03 Notes\n",
    "### Created by Christopher Kinson\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Assigning objects](#assigning-objects)  \n",
    "- [Web scraping for accessing and importing data](#web-scraping)  \n",
    "- [Handling dates and times](#handling-dates-and-times)  \n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "## <a name=\"assigning-objects\"></a>Assigning objects\n",
    "\n",
    "In Python, object assignment is done with an assignment operator, `=` as in `x=10`.  \n",
    "\n",
    "We've already assigned objects in Python. If you need proof, review the notes from Week 02. With assigning objects, one important thing to notice is the acceptable naming conventions of your programming language. As mentioned in Tip 1, most programming languages won't like kebab-case. Thus, I advise you to use one of the following cases: camelCase, PascalCase, or snake_case. \n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "## <a name=\"web-scraping\"></a>Web scraping for accessing and importing data\n",
    "\n",
    "Web scraping can be a fun way to explore information provided on a website in order to store it and analyze it for statistical/academic purposes. \n",
    "\n",
    "**Because the data contained in the City of Urbana's Data Portal is part of the US government, students outside of the US may have limited or no access based on their current government policies. Regardless, the web scraping section of the notes are still conceptually important. All students in this course are expected to learn and demonstrate their understanding of the concepts covered in these notes.**\n",
    "\n",
    "Recall, [City of Urbana's Rental Inspection Grades Listings Data - structured comma-separated](https://github-dev.cs.illinois.edu/stat440-fa21/stat440-fa21-course-content/raw/master/data/rental-inspections-grades-data01.csv) that I like so much. Notice that when we access and import it (the structured comma-separated file), we can get a better view of the columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1730 entries, 0 to 1729\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Property Address  1730 non-null   object\n",
      " 1   Parcel Number     1730 non-null   int64 \n",
      " 2   Inspection Date   1730 non-null   object\n",
      " 3   Grade             1730 non-null   object\n",
      " 4   License Status    1730 non-null   object\n",
      " 5   Expiration Date   1456 non-null   object\n",
      " 6   Mappable Address  1730 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 94.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "rental_data = pd.read_csv('https://raw.github-dev.cs.illinois.edu/stat440-fa21/stat440-fa21-course-content/master/data/rental-inspections-grades-data01.csv?token=AAABJGZ6OHL3GMHOK3DVMSTBGEUWS')\n",
    "rental_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is about housing that people pay rent money for and the grades of these housing units upon inspection. The specific columns are: Property Address, Parcel Number, Inspection Date, Grade, License Status, Expiration Date, and Mappable Address. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Property Address', 'Parcel Number', 'Inspection Date', 'Grade',\n",
       "       'License Status', 'Expiration Date', 'Mappable Address'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rental_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you've lived long enough to understand property, then you know that every county across America has public records of almost all properties and their owners. This includes Champaign County. These property records are stored by the [Office of the Champaign County Assessor](http://www.co.champaign.il.us/ccao/assessor.php). These housing units belong to property owners who may or may not live at the same address as the property they are renting. What if we were to look online, find the owner's name and address to see if it matches that of the property they're renting out? \n",
    "\n",
    "First, let's go to the Property Record Search portion of the county's website. See image below.\n",
    "\n",
    "![](https://uofi.box.com/shared/static/3sf6f8djudewb0ch9zw8pdmmj6y1vuj9.png)\n",
    "\n",
    "Which takes us here. See image below.\n",
    "\n",
    "![](https://uofi.box.com/shared/static/tkuofhfr3cytzwce9xovnat5qcmg9dmy.png)\n",
    "\n",
    "The property record search allows for searching by parcel number. Our dataset has a column by the exact same name. So let's try searching the records for the first parcel number in our dataset: 922116177018. See image below.\n",
    "\n",
    "![](https://uofi.box.com/shared/static/mshnwcds23ee9u2h7g1lm7g7p9v0d7th.png)\n",
    "\n",
    "Running that search takes us here. See image below.\n",
    "\n",
    "![](https://uofi.box.com/shared/static/k6m6zjmy6c17fqfafd916j8denzhuc02.png)\n",
    "\n",
    "The owners of parcel number 922116177018 don't share the same address as the rental property address, at least not on record.\n",
    "\n",
    "Doing this would be tedious to do for all 1730 properties in this dataset. Web scraping is a data accessing tool that can automate the process of retrieving property owner information from the county's website.\n",
    "\n",
    "We will use the **BeautifulSoup** and **requests** libraries, to scrape or harvest data from the Office of the Champaign County Assessor's website. I am basing the notes below on [\"Harvesting the web with rvest\"](https://rvest.tidyverse.org/articles/harvesting-the-web.html) - an **rvest** vignette written by Demytro Perepolkin, as well as [\"Beautiful Soup: Build a Web Scraper With Python\"](https://realpython.com/beautiful-soup-web-scraper-python/#scraping-the-monster-job-site) a Python blog post by Martin Breuss.\n",
    "\n",
    "We're going to go directly to the table containing the Owner Name and Address shown above and right-click on the section where the owner names appear. Click \"Inspect\" or \"Inspect Page\" and pay attention to the text highlighted in the image below.\n",
    "\n",
    "![](https://uofi.box.com/shared/static/90k8q8ppl13vv0yav8h6m9ncknp1i7jn.png)\n",
    "\n",
    "This text (which is a series of HTML tags) is necessary for us to extract the owner names. The tags represent HTML reference points for how to identify the the information we truly want, which is in the table of Owner Name and Address. To figure out which html tags are going to get us what we need will take some trial and error. That's okay, but takes up time. Eventually we have our desired result (took me 30 minutes to try out several combinations of html tags) based on the two html tags: \".col-xs-4\" and \".inner-value\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<td class=\"col-xs-4\">\n",
      "<div class=\"inner-label\">Parcel Number</div>\n",
      "<div class=\"inner-value\">92-21-16-177-018</div>\n",
      "</td>, <td class=\"col-xs-4\" rowspan=\"3\">\n",
      "<div class=\"inner-label\">Site Address</div>\n",
      "<div class=\"inner-value\">\n",
      "                        607   GLOVER AVE<br/>\n",
      "                        URBANA, IL 61802\n",
      "                    </div>\n",
      "</td>, <td class=\"col-xs-4\" rowspan=\"3\">\n",
      "<div class=\"inner-label\">Owner Name &amp; Address</div>\n",
      "<div class=\"inner-value\" style=\"white-space:pre-line\"> CORA MAE PROPERTIES LLC, \n",
      "LUKE SHERMAN\n",
      "PO BOX 101\n",
      "CHAMPAIGN, IL, 61824-0101 </div>\n",
      "</td>]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url1 = \"https://champaignil.devnetwedge.com/parcel/view/922116177018/2020\"\n",
    "page1 = requests.get(url1)\n",
    "soup1 = BeautifulSoup(page1.text, 'html.parser')\n",
    "owner_names1 = soup1.find_all('td',{'class':'col-xs-4'})\n",
    "print(owner_names1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CORA MAE PROPERTIES LLC, \n",
      "LUKE SHERMAN\n",
      "PO BOX 101\n",
      "CHAMPAIGN, IL, 61824-0101 \n"
     ]
    }
   ],
   "source": [
    "for owner_names in owner_names1:\n",
    " owner_names2 = owner_names.find('div', class_='inner-value')\n",
    "print(owner_names2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! \n",
    "\n",
    "We used web scraping to grab the first property's owner names according to the Parcel Number 922116177018, and the result shows the owner name and address separated by new line characters `\\n`. Again, we see this information verifies that the owner address is not the same as the rental property's address.\n",
    "\n",
    "Now, let's do this for all properties. The key will be to loop or vectorize this process. *Actually in the chunk below I am only doing this for the first 5 properties since this process takes a long time for all 1730 properties.* The most important thing that is changing with each iteration of a loop should be the parcel number. We can use an index-controlled loop such that that the index value of parcel number column increments until we reach 1730. Putting it all together, we yield the following vector of owner names and address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_url = 'https://champaignil.devnetwedge.com/parcel/view/'\n",
    "owner_names6 = ['']*len(rental_data)\n",
    "for i in range(5):\n",
    "    url = root_url + str(rental_data['Parcel Number'].iloc[i]) + '/2020'\n",
    "    response = requests.get(url)\n",
    "    soup2 = BeautifulSoup(response.text,'html.parser')\n",
    "    owner_names5 = soup2.find_all('td',{'class':'col-xs-4'})\n",
    "    for oN in owner_names5:\n",
    "        owner_names6[i] = oN.find('div', class_='inner-value').text\n",
    "print(owner_names6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice!\n",
    "\n",
    "But there's a better way!!\n",
    "\n",
    "Let's use the SelectorGadget tool! The SelectorGadget tool (read about it and set it up in your browser https://rvest.tidyverse.org/articles/selectorgadget.html) allows one to inspect the particular part of the web page and better narrow down the html tags. This saves time and greatly reduces the effort of trial and error to grab the information in the Owner Name and Address section of the website.\n",
    "\n",
    "Using this tool, we selected the table we want and de-selected the Site Address portion of the table next to it. Doing so improved the SelectorGadget estimate of the html tags we *do* want (seen at bottom highlighted in blue).\n",
    "\n",
    "![](https://uofi.box.com/shared/static/as4pbwxnxdod2q1ah4aopn88im8xony2.png)\n",
    "\n",
    "This resulted in two html tags: \".col-xs-4:nth-child(3)\" and \".inner-value\". Trying those two tags out results in the more direct Owner Name and Address information. **Notice that we use the `select()` function with the `soup1` object instead of the `find_all()` or `find()` functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"inner-value\" style=\"white-space:pre-line\"> CORA MAE PROPERTIES LLC, \n",
      "LUKE SHERMAN\n",
      "PO BOX 101\n",
      "CHAMPAIGN, IL, 61824-0101 </div>]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url1 = \"https://champaignil.devnetwedge.com/parcel/view/922116177018/2020\"\n",
    "page1 = requests.get(url1)\n",
    "soup1 = BeautifulSoup(page1.text)\n",
    "owner_names1 = soup1.select('.col-xs-4:nth-child(3) .inner-value')\n",
    "print(owner_names1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' CORA MAE PROPERTIES LLC, \\nLUKE SHERMAN\\nPO BOX 101\\nCHAMPAIGN, IL, 61824-0101 ']\n"
     ]
    }
   ],
   "source": [
    "owner_names2 = [names1.text for names1 in owner_names1]\n",
    "print(owner_names2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now looping over the first 5 parcel numbers with this more direct CSS selection yields..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' CORA MAE PROPERTIES LLC, \\nLUKE SHERMAN\\nPO BOX 101\\nCHAMPAIGN, IL, 61824-0101 ', ' WOMACK, DEBORAH J & MICHAEL\\n803 N OAKWOOD ST\\nEFFINGHAM, IL, 62401-3241 ', ' RUBIN, RACHAEL\\n212 N CENTRAL AVE\\nURBANA, IL, 61801-2606 ', ' HARPER, CRAIG & JAMES E\\n1173 COUNTY ROAD 2400 E\\nST JOSEPH, IL, 61873-9726 ', ' WAMPLER, JOSEPH\\nCOLONY PROPERTY MANAGEMENT\\n701 DEVONSHIRE DR\\nCHAMPAIGN, IL, 61820-7337 ']\n"
     ]
    }
   ],
   "source": [
    "root_url = 'https://champaignil.devnetwedge.com/parcel/view/'\n",
    "owner_names4 = ['']*len(rental_data)\n",
    "o_n = ['']*len(rental_data)\n",
    "for i in range(5):\n",
    "    url = root_url + str(rental_data['Parcel Number'].iloc[i]) + '/2020'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    owner_names3 = soup.select('.col-xs-4:nth-child(3) .inner-value')\n",
    "    for oN in owner_names3:\n",
    "        owner_names4[i] = [names2.text for names2 in owner_names3]\n",
    "owner_names04 = []\n",
    "for item in owner_names4:\n",
    "    owner_names04 += item\n",
    "print(owner_names04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! \n",
    "\n",
    "Below is a final note on web scraping.\n",
    "\n",
    "Sometimes people abuse this exploration and overdo it on web scraping, which is why certain aspects of web scrapers are illegal or at the least, frowned upon. When you web scrape be cautious of how often you are hitting a particular website. It might be best to do the scraping in chunks over a few days if you are attempting to gather lots of data.\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "## <a name=\"handling-dates-and-times\"></a>Handling dates and times\n",
    "\n",
    "When a data set contains date and time information in the fields (columns), the dates and times may be correctly imported internally by the programming language, but misinterpreted externally by the users. Most programming languages, operating systems, and software internally store dates and times as a value in reference to some specific date. For example, in SAS, the reference date is January 1, 1960. In R and Python, internal dates and times are in reference to January 1, 1970. You may find it necessary to convert character strings into date values or re-format existing date values. \n",
    "\n",
    "Below is a table of standard date and time formats that work across Python and R. For more information about your programming language's specific formatting for dates, see [Python with datetime module](https://www.w3schools.com/python/python_datetime.asp), [R with the tiyverse](https://r4ds.had.co.nz/dates-and-times.html), and [R with base R functionality](https://www.statmethods.net/input/dates.html). \n",
    "\n",
    "Code | Meaning\n",
    "---|---\n",
    "\\%a\t| Abbreviated weekday name\t\n",
    "\\%A\t| Full weekday name\n",
    "\\%b\t| Abbreviated month name\t\n",
    "\\%B\t| Full month name\n",
    "\\%c\t| Date and time\t\n",
    "\\%d\t| Day of the month (0-31)\n",
    "\\%H\t| Hours (24 hour)\t\n",
    "\\%I\t| Hours (12 hour)\n",
    "\\%j\t| Day of the year numbered (000-366)\n",
    "\\%m\t| Month numbered (01-12)\n",
    "\\%M\t| Minute numbered (00-59)\t\n",
    "\\%p\t| AM/PM\n",
    "\\%S\t| Second numbered (00-61)\t\n",
    "\\%U\t| Week of the year starting on Sunday numbered (00-53)\n",
    "\\%w\t| Weekday starting on Sunday numbered (0-6)\t\n",
    "\\%W\t| Week of the year starting on Monday numbered (00-53)\n",
    "\\%y\t| 2-digit year\t\n",
    "\\%Y\t| 4-digit year\n",
    "\\%z\t| Offset from UTC\t\n",
    "\\%Z\t| Time zone (character)\n",
    "\n",
    "Let's see this in action with the City of Urbana's [Rental Inspection Grades Listings Data - structured comma-separated file](https://github-dev.cs.illinois.edu/stat440-fa21/stat440-fa21-course-content/raw/master/data/rental-inspections-grades-data01.csv). Let's focus on the Inspection Date and Expiration Date columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Property Address', 'Parcel Number', 'Inspection Date', 'Grade',\n",
       "       'License Status', 'Expiration Date', 'Mappable Address'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rental_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1730 entries, 0 to 1729\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Inspection Date  1730 non-null   object\n",
      " 1   Expiration Date  1456 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 27.2+ KB\n"
     ]
    }
   ],
   "source": [
    "rental_dates = rental_data[[\"Inspection Date\", \"Expiration Date\"]]\n",
    "rental_dates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       07/24/2015\n",
       "1       08/17/2011\n",
       "2       04/26/2010\n",
       "3       06/12/2013\n",
       "4       07/08/2013\n",
       "           ...    \n",
       "1725    12/18/2017\n",
       "1726    12/16/2019\n",
       "1727    11/04/2011\n",
       "1728    04/18/2016\n",
       "1729    05/18/2016\n",
       "Name: Inspection Date, Length: 1730, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rental_dates[\"Inspection Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       10/14/2021\n",
       "1       10/14/2021\n",
       "2              NaN\n",
       "3       10/14/2021\n",
       "4       10/14/2020\n",
       "           ...    \n",
       "1725    10/14/2021\n",
       "1726    10/14/2021\n",
       "1727    10/14/2021\n",
       "1728           NaN\n",
       "1729           NaN\n",
       "Name: Expiration Date, Length: 1730, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rental_dates[\"Expiration Date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two date columns are stored in Python in a type that is not datetime format. We are going to **coerce** the current format to be date format with the `to_datetime()` function within **pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2015-07-24\n",
       "1      2011-08-17\n",
       "2      2010-04-26\n",
       "3      2013-06-12\n",
       "4      2013-07-08\n",
       "          ...    \n",
       "1725   2017-12-18\n",
       "1726   2019-12-16\n",
       "1727   2011-11-04\n",
       "1728   2016-04-18\n",
       "1729   2016-05-18\n",
       "Name: Inspection Date, Length: 1730, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rental_dates01 = pd.to_datetime(rental_dates[\"Inspection Date\"])\n",
    "rental_dates01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2021-10-14\n",
       "1      2021-10-14\n",
       "2             NaT\n",
       "3      2021-10-14\n",
       "4      2020-10-14\n",
       "          ...    \n",
       "1725   2021-10-14\n",
       "1726   2021-10-14\n",
       "1727   2021-10-14\n",
       "1728          NaT\n",
       "1729          NaT\n",
       "Name: Expiration Date, Length: 1730, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rental_dates02 = pd.to_datetime(rental_dates[\"Expiration Date\"])\n",
    "rental_dates02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can add the format argument to be more specific about how the date exists instead of relying on Python to guess for us. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2021-10-14\n",
       "1      2021-10-14\n",
       "2             NaT\n",
       "3      2021-10-14\n",
       "4      2020-10-14\n",
       "          ...    \n",
       "1725   2021-10-14\n",
       "1726   2021-10-14\n",
       "1727   2021-10-14\n",
       "1728          NaT\n",
       "1729          NaT\n",
       "Name: Expiration Date, Length: 1730, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rental_dates03 = pd.to_datetime(rental_dates[\"Expiration Date\"], format=\"%m/%d/%Y\")\n",
    "rental_dates03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END OF NOTES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
